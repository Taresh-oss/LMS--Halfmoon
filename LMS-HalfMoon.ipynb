{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the dot product of weight matrix and input matrix\n",
    "def zipper(x,w):\n",
    "    perceptronrule_Mul=np.dot(w,x)\n",
    "    return perceptronrule_Mul\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is basically the perceptron rule and is used to train the model and provide a final weight matrix that can be \n",
    "#used for caluclating testing accuracy during testing phase\n",
    "def LMS(feature,lr,target,epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    bias=0\n",
    "    numb_featureval=len(feature.values[0])\n",
    "    weight_value=[]\n",
    "    rmse_error=[]\n",
    "    \n",
    "    \n",
    "    accuracy={}\n",
    "    acc=[]\n",
    "    max_acc=0\n",
    "    \n",
    "    w=[0 for i in range(numb_featureval)] # Initializing the weight matrix with values as 1 with the number of values being the number of inputs\n",
    "    \n",
    "    #Iterating the epochs for training\n",
    "    for itera in range(epochs):\n",
    "        predicted_label=[]\n",
    "        error_value=[]\n",
    "        for x,y in zip(feature.values,target.values): # iterating the input values and the target values simultaneously\n",
    "                                                      #so that the values can be compared for the same index.\n",
    "            \n",
    "            product=zipper(x,w) #zipper function called which returns the dot product of weight and input which is then compared\n",
    "                                #with the bias to finally get the predicted label\n",
    "            \n",
    "            predicted_class= 1 if product>0 else -1\n",
    "            \n",
    "            #storing the predicted values in a list corresponding to their row index so that it can be compared to its actual target values\n",
    "            predicted_label.append(predicted_class)\n",
    "            \n",
    "            error=0\n",
    "            \n",
    "            #Weight and bias updation if the prdicted value doesnt match with the target labels\n",
    "             \n",
    "            error=y-product  #calculating error which is (desired output- input*weight) \n",
    "            w=w+(lr*x*error) #weight updation as per the error\n",
    "\n",
    "            error_value.append(error) #appending the errors for a particular epoch into a list, which is further used for rmse calculation\n",
    "        square=0\n",
    "        mean=0\n",
    "        root=0\n",
    "        \n",
    "        #Squaring and adding the values of errors, followed by taking mean and root of the computed answer\n",
    "        for i in error_value:\n",
    "            square += (i**2) \n",
    "        #Calculate Mean  \n",
    "        mean = (square / (float)(len(error_value)))\n",
    "        #Calculate Root \n",
    "        root = math.sqrt(mean)\n",
    "        rmse_error.append(root)\n",
    "        \n",
    "        \n",
    "        #Calling the accuracy_score function of sklearn to calculate the accuracy for each epoch by passing the predicted labels list\n",
    "        #the target labels as arguements\n",
    "        \n",
    "        acc.append(accuracy_score(predicted_label,target.values))\n",
    "\n",
    "        weight_value.append(w)\n",
    "          \n",
    "        #print(root)\n",
    "        #checking and storing the maximum accuracy and getting the epoch with the maximum accuracy to extract the weights at that epoch\n",
    "        if(acc[itera-1]>max_acc):\n",
    "                   \n",
    "            max_acc=acc[itera-1]\n",
    "            epoch_max_acc=itera\n",
    "            \n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "            \n",
    "    print(\"********************************************* Training Starts here **********************************************\")\n",
    "    print(\"\")\n",
    "    print(\"RMSE values as per Epochs: \")\n",
    "    print(\"\")\n",
    "    for i in rmse_error:\n",
    "        print(i)\n",
    "    print(\"\")\n",
    "    print(\"Accuracy: \",max_acc,\"Error rate: \",(1-max_acc)) \n",
    "    print(\"Training Time: \",round(elapsed_time,3))\n",
    "    return weight_value[epoch_max_acc] #Returning the weight that led to maximum accuracy\n",
    "\n",
    "\n",
    "    \n",
    "                    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************* Training Starts here **********************************************\n",
      "\n",
      "RMSE values as per Epochs: \n",
      "\n",
      "0.8630311787990561\n",
      "0.6662219971683386\n",
      "0.5617888084663495\n",
      "0.5102875886784338\n",
      "0.486010951371721\n",
      "0.4746683563776775\n",
      "0.4692404360202154\n",
      "0.4665077306612291\n",
      "0.4650324712155386\n",
      "0.4641719625433881\n",
      "0.4636325432878378\n",
      "0.4632743231808747\n",
      "0.4630264900381704\n",
      "0.4628504046258794\n",
      "0.4627232486627239\n",
      "0.4626305543915394\n",
      "0.46256262585431734\n",
      "0.46251270938812716\n",
      "0.46247598293666625\n",
      "0.46244895162466737\n",
      "0.4624290603124906\n",
      "0.4624144317447294\n",
      "0.46240368306042173\n",
      "0.4623957942371512\n",
      "0.46239001246555717\n",
      "0.4623857820868395\n",
      "0.46238269303051655\n",
      "0.46238044277553786\n",
      "0.46237880825292305\n",
      "0.46237762507964075\n",
      "0.4623767722077471\n",
      "0.4623761605768431\n",
      "0.4623757247270894\n",
      "0.46237541660183407\n",
      "0.4623752009695732\n",
      "0.4623750520433139\n",
      "0.4623749509851752\n",
      "0.4623748840652772\n",
      "0.4623748413040972\n",
      "0.46237481547194603\n",
      "0.46237480135215864\n",
      "0.4623747951989298\n",
      "0.46237479433876005\n",
      "0.46237479687780675\n",
      "0.46237480148727617\n",
      "0.4623748072462923\n",
      "0.46237481352706405\n",
      "0.46237481991114215\n",
      "0.4623748261285152\n",
      "0.4623748320134509\n",
      "\n",
      "Accuracy:  0.971 Error rate:  0.029000000000000026\n",
      "Training Time:  0.839\n",
      "\n",
      "\n",
      "********************************************** Testing starts here ***************************************************\n",
      "\n",
      "RMSE:  0.4520868067533158\n",
      "Accuracy:  0.9705 Error rate :  0.02949999999999997\n",
      "Testing Time:  0.008\n"
     ]
    }
   ],
   "source": [
    "#This function uses parameters like radius, ditance between two moons, number of samples in total and width as per which\n",
    "#half moon will be generated and the data points will be stored along with their labels.\n",
    "\n",
    "features=3 #number of attributes +label column\n",
    "instances=3000\n",
    "r=10\n",
    "d=0\n",
    "w=4\n",
    "\n",
    "\n",
    "\n",
    "#First we need to check whether the number of samples are even or not\n",
    "if (instances%2!=0) :\n",
    "    print(\"*****Error****** Number of samples are not valid; They should be even \")\n",
    "    instances=instances+1\n",
    "\n",
    "#Matrix initialization of samples with 0 as initial value for x,y and label values.\n",
    "valuesofSamples=np.zeros((features,instances),dtype=int)\n",
    "#print(valuesofSamples)\n",
    "\n",
    "# Boundary condition checking\n",
    "if (r<w/2):\n",
    "    print(\"*****Error******  Radius is not enough\")\n",
    "\n",
    "#Creating random float values of x and y coordinates of half the instances\n",
    "randomval=np.random.random((2,int(instances/2)))\n",
    "#print (randomval)\n",
    "\n",
    "radii=(r-w/2)+w*randomval[0][:]\n",
    "\n",
    "#Calculating outer radius for one half moon\n",
    "theta=np.pi*randomval[1][:]\n",
    "\n",
    "#Creation of datasets for both the half moons\n",
    "x_class1=np.multiply(radii,np.cos(theta)) #X coordinate for 1st half data points\n",
    "y_class1=np.multiply(radii,np.sin(theta)) #y coordinate for 1st half data points\n",
    "label_class1=np.ones((1,len(x_class1)),dtype=int) #providing label as 1 to the entire 1st half moon data\n",
    "label_class1=np.hstack(label_class1)\n",
    "                     \n",
    "x_class2=np.multiply(radii,np.cos(-theta))+r #X coordinate for 2nd half data points\n",
    "y_class2=np.multiply(radii,np.sin(-theta))-d #y coordinate for 2nd half data points\n",
    "label_class2=-1*np.ones((1,len(x_class2)),dtype=int) #providing label as -1 to the 2nd half moon data\n",
    "label_class2=np.hstack(label_class2)\n",
    "                     \n",
    "\n",
    "\n",
    "#Now we will create a single matrix with all the x,y coordinates of all the points belonging to both the halves\n",
    "#using a nested list functionality,with their corresponding labels\n",
    "valuesofSamples[0,:]=np.concatenate([x_class1,x_class2])\n",
    "valuesofSamples[1,:]=np.concatenate([y_class1,y_class2])\n",
    "\n",
    "valuesofSamples[2,:]=np.concatenate(([label_class1,label_class2]))\n",
    "\n",
    "#converting to dataframe and Transposing it to get columns on the top\n",
    "df=(pd.DataFrame(valuesofSamples)).T\n",
    "\n",
    "DF=df.rename(columns={0:'x',1:'y',2:'labels'}) #Renaming the column name as per index\n",
    "\n",
    "scalerObjct=MaxAbsScaler()  #Normalizing thee valus of the datasetusing MaxAbsScaler\n",
    "Normalizeddf=scalerObjct.fit_transform(DF)\n",
    "df_scaled = pd.DataFrame(Normalizeddf, columns=DF.columns) \n",
    "\n",
    "df_scaled = df_scaled.astype({\"labels\": int}) #Converting label column values to int\n",
    "df_scaled.sample(frac=1) # Randomizing the whole dataset\n",
    "DF_train,DF_test=train_test_split(df_scaled, test_size=0.6665) #splitting the dataset with 1000 training and 2000 testing data points\n",
    "#Separating the feature data and label data for the training set\n",
    "feature_valTrain=DF_train[['x','y']] \n",
    "Label_train=DF_train['labels']\n",
    "\n",
    "\n",
    "final_weight=LMS(feature_valTrain,0.001,Label_train,50) #Storing the weight matrix that led to maximum accuracy \n",
    "                                                                   #during training phase when PerceptronRule is called with \n",
    "                                                                   #feature, learning rate as 0.01, label and epoch as 600 as arguements.\n",
    "\n",
    "#Separating the feature data and label data for the testing set        \n",
    "feature_valTest=DF_test[['x','y']]\n",
    "Label_test=DF_test['labels']\n",
    "\n",
    "list_test=[] #list to store predicted labels during testing 2000 data points with their original labels\n",
    "\n",
    "#Predicting values with test data and caluclating accuracy similar to training phase but with weights fixed as final_weights\n",
    "#received from training phase after calculating accuracy\n",
    "\n",
    "calculated_out=[] #to store i*w while testing and then using it for rmse\n",
    "\n",
    "test_time=time.time() #Starting the timer to calculate the testing time\n",
    "\n",
    "for x,l in zip(feature_valTest.values, Label_test.values):\n",
    "    result=zipper(x,final_weight)   \n",
    "    answ=1 if result>0 else -1\n",
    "    list_test.append(answ)\n",
    "    calculated_out.append(result)    \n",
    "\n",
    "test_accuracy=accuracy_score(list_test,Label_test.values)\n",
    "mse = mean_squared_error(calculated_out, Label_test.values) #Getting mse calculated\n",
    "rmse=np.sqrt(mse)\n",
    "endtime_test=time.time()-test_time #calculating testing time\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"********************************************** Testing starts here ***************************************************\")\n",
    "print(\"\")\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"Accuracy: \",test_accuracy,\"Error rate : \",(1-test_accuracy))\n",
    "print(\"Testing Time: \",round(endtime_test,3))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
